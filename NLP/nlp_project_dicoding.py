# -*- coding: utf-8 -*-
"""NLP PROJECT DICODING

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MY9AuLwbREAfTr10GsdmxI_fiGoojIIR

**DATA DIRI**

**NAMA : MUHAMMAD ISMAIL**

**DOMISILI : SURABAYA, JAWA TIMUR**

**NLP PROJECT**
"""

import tensorflow as tf
#mengecek version dari tensorflow
tf.__version__

"""**EKSTRAKSI FILE**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

!pip install kaggle

#mengupload API key akun kaggle
from google.colab import files
files.upload()

# membuat directory dari kaggle.json
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

#download dataset
!kaggle datasets download -d hgultekin/bbcnewsarchive

# unzip dan lihat list dataset
!mkdir bbcnewsarchive
!unzip bbcnewsarchive.zip -d bbcnewsdata

"""**MEMBUAT DATAFRAME**

"""

#mengubah file csv yang didapatkan ke dataframe
#penambahan sep='\t' memudahkan mesin untuk membaca dataframe dan menghindari eror
df = pd.read_csv('bbcnewsdata/bbc-news-data.csv',sep='\t')
df.head()

df.shape

"""**DATA CLEANING**"""

new_df = df.drop(columns=['filename'])
new_df

#mengecek apakah ada yang null
new_df.isnull().sum()

new_df.info()

"""**VISUALISASI DATA**"""

#bentuk bar
plt.figure(figsize =(10,6))
sns.set_style("whitegrid")
sns.countplot(new_df['category'], palette="Set3")

"""**ENCODING**"""

#mengambil kolom category
category = pd.get_dummies(new_df.category)
#one-hot-encoding kolom category
new_df = pd.concat([new_df,category],axis = 1)
#mengedrop kolom category
new_df = new_df.drop(columns=['category'])
new_df.tail(10)

new_df.head()

"""**IMPORT TOKENIZER DAN SCIKITLEARN SERTA BERBAGAI KOMPONEN PENTING LAIN**

"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

"""**MEMBUAT LABEL DAN FEATURE**"""

label = new_df[["business", "entertainment", "politics", "sport", "tech"]].values
content = new_df['title'].values + '' + new_df['content'].values

content

label

#membagi data train dan data test
content_train, content_test, label_train, label_test = train_test_split(content,label,test_size=.2)

#membuat model tokenizer
tokenizer = Tokenizer(num_words= 12000, oov_token= "<OOV>")

#melatih tokenizer dengan data train
tokenizer.fit_on_texts(content_train)
sekuens_latih = tokenizer.texts_to_sequences(content_train)
padded_latih = pad_sequences(sekuens_latih, maxlen = 300, truncating='post') 

#membuat sequence dan padding dari data testing
sekuens_test = tokenizer.texts_to_sequences(content_test)
padded_test = pad_sequences(sekuens_test, maxlen = 300, truncating='post')

padded_test.shape

padded_latih.shape

model = tf.keras.Sequential([
     tf.keras.layers.Embedding(input_dim=12000, output_dim= 64, input_length = 300),
     tf.keras.layers.LSTM(128),
     tf.keras.layers.Dense(64, activation='relu'),
     tf.keras.layers.Dense(64, activation='relu'),
     tf.keras.layers.Dropout(0.5),
     tf.keras.layers.Dense(5, activation='softmax')
     ])

model.compile(optimizer = 'adam',
              loss = 'categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#membuat callback agar menghentikan epoch bila akurasi sesuai dengan yang diinginkan
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') >0.98 and logs.get('loss') < 0.05 and logs.get('val_accuracy') > 0.9):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

Predict = model.fit(
    padded_latih,
    label_train, 
    epochs = 50, 
    validation_data = (padded_test, label_test), 
    verbose = 2, 
    callbacks =[callbacks],
    validation_steps = 30
)

plt.plot(Predict.history['accuracy'])
plt.plot(Predict.history['val_accuracy'])
plt.title('Akurasi Model')

plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='lower right')

plt.show()

plt.plot(Predict.history['loss'])
plt.plot(Predict.history['val_loss'])
plt.title('Loss Model')

plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')

plt.show()